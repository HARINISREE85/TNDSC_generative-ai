{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1032238,
          "sourceType": "datasetVersion",
          "datasetId": 568973
        }
      ],
      "dockerImageVersionId": 29994,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebooke0868cf692",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARINISREE85/TNDSC_generative-ai/blob/main/music%20composition%20and%20generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'gtzan-dataset-music-genre-classification:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F568973%2F1032238%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240331%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240331T074157Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D758b11151975f1c717230f63be21d7842b77f02c4d549c57f0fc684fb9884d9d065f8cc6c753b2f79e8d3cea74e1eda21993f34d6cbf200882e7bb38e798f651f621fc942bc6373d5fab0faa69da7c4ecb3d3e1becab198c224504e08d1aed7f05abccf933172dbbb48d3dcacdcefa903cff56583b52404dbee157b77e28424f280ee90c6d598f358aeac4a083d656a6e321ee264f02990695077a2396bf9fca4c0bfd49a6351262e51347476e329c7e1c790b9d7d7e7b91faf68f2a37e63364289573f98c9f7b0ef803d65f9c7a8b4e3063dcd0d30fdb6bdcc0ffb68f5b6a9738e9e7ce29be51e60938d2621f820d0de55c943670d06678f75937d30b831638'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WJPjtdBqdapA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate music with Variational AutoEncoder\n",
        "![iame_intro](https://i.ytimg.com/vi/WI1xExDWVF0/maxresdefault.jpg)"
      ],
      "metadata": {
        "id": "QXOxYAXedapG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "This work is inspired by the research paper [Jukebox: A Generative Model for Music](https://cdn.openai.com/papers/jukebox.pdf). In this notebook, I have developed a generative model that could generate music from a variational autoencoder trained with a category of music. I have selected the jazz and classical music categories. The entire model is implemented in TensorFlow and used Librosa for audio processing. The input sampling rate is 3000 for processing the audio file into a readable array."
      ],
      "metadata": {
        "id": "JoUfZnm3dapJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Variational AutoEncoder?\n",
        " VAE is an autoencoder whose encodings distribution is regularised during the training in order to ensure that its latent space has good properties allowing us to generate some new data. A variational autoencoder (VAE) provides a probabilistic manner for describing an observation in latent space.\n",
        "![VAE](https://miro.medium.com/max/3080/1*82EghOQR2Z5uuwUjFiVV2A.png)\n",
        "\n",
        "Source -  [The Intuition Behind Variational Autoencoders](https://medium.com/@realityenginesai/understanding-variational-autoencoders-and-their-applications-81a4f99efc0d), [Variational autoencoders.](https://www.jeremyjordan.me/variational-autoencoders/)"
      ],
      "metadata": {
        "id": "ib2PgRCNdapJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n",
        "#!pip install tensorflow-addons\n",
        "#!pip install --upgrade --ignore-installed tensorflow\n",
        "#!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-11-21T00:57:54.095272Z",
          "iopub.execute_input": "2021-11-21T00:57:54.095776Z",
          "iopub.status.idle": "2021-11-21T00:58:24.064231Z",
          "shell.execute_reply.started": "2021-11-21T00:57:54.095728Z",
          "shell.execute_reply": "2021-11-21T00:58:24.063363Z"
        },
        "trusted": true,
        "id": "bk0h_iNldapK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import time\n",
        "import IPython.display as ipd\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "9dW17ecr5IYC",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:24.067199Z",
          "iopub.execute_input": "2021-11-21T00:58:24.067559Z",
          "iopub.status.idle": "2021-11-21T00:58:29.309125Z",
          "shell.execute_reply.started": "2021-11-21T00:58:24.067518Z",
          "shell.execute_reply": "2021-11-21T00:58:29.308204Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=123\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "Rf_iJJoWEkEF",
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:29.32471Z",
          "iopub.execute_input": "2021-11-21T00:58:29.325209Z",
          "iopub.status.idle": "2021-11-21T00:58:30.940037Z",
          "shell.execute_reply.started": "2021-11-21T00:58:29.325166Z",
          "shell.execute_reply": "2021-11-21T00:58:30.939185Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "BATCH_SIZE = 10\n",
        "test_size = 10000\n",
        "epochs = 20\n",
        "# set the dimensionality of the latent space to a plane for visualization later\n",
        "latent_dim = 2\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "BASE_PATH = '../input/gtzan-dataset-music-genre-classification/Data/genres_original'"
      ],
      "metadata": {
        "id": "BLdVyNVHrFF1",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:36.32564Z",
          "iopub.execute_input": "2021-11-21T01:12:36.325964Z",
          "iopub.status.idle": "2021-11-21T01:12:36.332451Z",
          "shell.execute_reply.started": "2021-11-21T01:12:36.325934Z",
          "shell.execute_reply": "2021-11-21T01:12:36.331575Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "L-xd36ThdapO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DatasetLoader(class_):\n",
        "    music_list = np.array(sorted(os.listdir(BASE_PATH+'/'+class_)))\n",
        "    train_music_1 = list(music_list[[0,52,19,39,71,12,75,85,3,45,24,46,88]]) #99,10,66,76,41\n",
        "    train_music_2 = list(music_list[[4,43,56,55,45,31,11,13,70,37,21,78]]) #65,32,53,22,19,80,89,\n",
        "    TrackSet_1 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_1]\n",
        "    TrackSet_2 = [(BASE_PATH)+'/'+class_+'/%s'%(x) for x in train_music_2]\n",
        "\n",
        "    return TrackSet_1, TrackSet_2"
      ],
      "metadata": {
        "id": "NtThS3oVWU85",
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:30.949566Z",
          "iopub.execute_input": "2021-11-21T00:58:30.950427Z",
          "iopub.status.idle": "2021-11-21T00:58:30.962268Z",
          "shell.execute_reply.started": "2021-11-21T00:58:30.950386Z",
          "shell.execute_reply": "2021-11-21T00:58:30.961304Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(file_):\n",
        "    data_, sampling_rate = librosa.load(file_,sr=3000, offset=0.0, duration=30)\n",
        "    data_ = data_.reshape(1,90001)\n",
        "    return data_\n",
        "map_data = lambda filename: tf.compat.v1.py_func(load, [filename], [tf.float32])"
      ],
      "metadata": {
        "id": "72nbIzueCYWq",
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:30.964176Z",
          "iopub.execute_input": "2021-11-21T00:58:30.965149Z",
          "iopub.status.idle": "2021-11-21T00:58:30.973156Z",
          "shell.execute_reply.started": "2021-11-21T00:58:30.965109Z",
          "shell.execute_reply": "2021-11-21T00:58:30.972175Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrackSet_1, TrackSet_2 = DatasetLoader('jazz')"
      ],
      "metadata": {
        "id": "Z-q0fDhfeek_",
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:30.97502Z",
          "iopub.execute_input": "2021-11-21T00:58:30.975983Z",
          "iopub.status.idle": "2021-11-21T00:58:31.027974Z",
          "shell.execute_reply.started": "2021-11-21T00:58:30.975943Z",
          "shell.execute_reply": "2021-11-21T00:58:31.027316Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sample original music"
      ],
      "metadata": {
        "id": "y2U0Jgt1dapQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = TrackSet_1[1]\n",
        "sample_, sampling_rate = librosa.load(sample,sr=3000, offset=0.0, duration=30)\n",
        "ipd.Audio(sample_,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:31.029946Z",
          "iopub.execute_input": "2021-11-21T00:58:31.030654Z",
          "iopub.status.idle": "2021-11-21T00:58:32.229861Z",
          "shell.execute_reply.started": "2021-11-21T00:58:31.030615Z",
          "shell.execute_reply": "2021-11-21T00:58:32.228976Z"
        },
        "trusted": true,
        "id": "nIQLoT75dapR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "plt.figure(figsize=(18,15))\n",
        "for i in range(4):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    j = load(TrackSet_1[i])\n",
        "    librosa.display.waveplot(j[0], sr=3000)\n",
        ""
      ],
      "metadata": {
        "id": "tTb_ETmUB80m",
        "execution": {
          "iopub.status.busy": "2021-11-21T00:58:32.231114Z",
          "iopub.execute_input": "2021-11-21T00:58:32.231455Z",
          "iopub.status.idle": "2021-11-21T00:58:35.237027Z",
          "shell.execute_reply.started": "2021-11-21T00:58:32.231423Z",
          "shell.execute_reply": "2021-11-21T00:58:35.236026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((TrackSet_1))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((TrackSet_2))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "WFrXrtoFPX1r",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:40.136732Z",
          "iopub.execute_input": "2021-11-21T01:12:40.137078Z",
          "iopub.status.idle": "2021-11-21T01:12:40.15943Z",
          "shell.execute_reply.started": "2021-11-21T01:12:40.137035Z",
          "shell.execute_reply": "2021-11-21T01:12:40.158703Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explaining the concept"
      ],
      "metadata": {
        "id": "a6QVKlVEdapS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder network\n",
        "This defines the approximate posterior distribution *q(z|x)*, which takes as input an observation and outputs a set of parameters for specifying the conditional distribution of the latent representation *z*. In this example, we simply model the distribution as a diagonal Gaussian, and the network outputs the mean and log-variance parameters of a factorized Gaussian. We output log-variance instead of the variance directly for numerical stability.\n",
        "## Decoder network\n",
        "This defines the conditional distribution of the observation *p(x|z)*, which takes a latent sample *z* as input and outputs the parameters for a conditional distribution of the observation. We model the latent distribution prior *p(z)* as a unit Gaussian.\n",
        "## Reparameterization\n",
        "To generate a sample *z* for the decoder during training, we can sample from the latent distribution defined by the parameters outputted by the encoder, given an input observation *x*. However, this sampling operation creates a bottleneck because backpropagation cannot flow through a random node.\n",
        "\n",
        "To address this, we use a reparameterization trick. In our example, we approximate *z* using the decoder parameters and another parameter *ϵ* as follows:\n",
        "\n",
        "z = μ + σ.ϵ\n",
        "\n",
        "Source: [Tensorflow](https://www.tensorflow.org/tutorials/generative/cvae)"
      ],
      "metadata": {
        "id": "STodaDuddapS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network architecture"
      ],
      "metadata": {
        "id": "FphHs5E7dapT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet1DBlock(tf.keras.Model):\n",
        "    def __init__(self, kernel_size, filters,type='encode'):\n",
        "        super(Resnet1DBlock, self).__init__(name='')\n",
        "\n",
        "        if type=='encode':\n",
        "            self.conv1a = layers.Conv1D(filters, kernel_size, 2,padding=\"same\")\n",
        "            self.conv1b = layers.Conv1D(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.norm1a = tfa.layers.InstanceNormalization()\n",
        "            self.norm1b = tfa.layers.InstanceNormalization()\n",
        "        if type=='decode':\n",
        "            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1,padding=\"same\")\n",
        "            self.norm1a = tf.keras.layers.BatchNormalization()\n",
        "            self.norm1b = tf.keras.layers.BatchNormalization()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(input_tensor)\n",
        "        x = self.conv1a(x)\n",
        "        x = self.norm1a(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x = self.conv1b(x)\n",
        "        x = self.norm1b(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)\n"
      ],
      "metadata": {
        "id": "qo4mCvIvvl25",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:43.250954Z",
          "iopub.execute_input": "2021-11-21T01:12:43.25134Z",
          "iopub.status.idle": "2021-11-21T01:12:43.264156Z",
          "shell.execute_reply.started": "2021-11-21T01:12:43.251305Z",
          "shell.execute_reply": "2021-11-21T01:12:43.26321Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(1,90001)),\n",
        "                layers.Conv1D(64,1,2),\n",
        "                Resnet1DBlock(64,1),\n",
        "                layers.Conv1D(128,1,2),\n",
        "                Resnet1DBlock(128,1),\n",
        "                layers.Conv1D(128,1,2),\n",
        "                Resnet1DBlock(128,1),\n",
        "                layers.Conv1D(256,1,2),\n",
        "                Resnet1DBlock(256,1),\n",
        "                # No activation\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(latent_dim+latent_dim)\n",
        "\n",
        "            ]\n",
        "        )\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "                layers.Reshape(target_shape=(1,latent_dim)),\n",
        "                Resnet1DBlock(512,1,'decode'),\n",
        "                layers.Conv1DTranspose(512,1,1),\n",
        "                Resnet1DBlock(256,1,'decode'),\n",
        "                layers.Conv1DTranspose(256,1,1),\n",
        "                Resnet1DBlock(128,1,'decode'),\n",
        "                layers.Conv1DTranspose(128,1,1),\n",
        "                Resnet1DBlock(64,1,'decode'),\n",
        "                layers.Conv1DTranspose(64,1,1),\n",
        "                # No activation\n",
        "                layers.Conv1DTranspose(90001,1,1),\n",
        "            ]\n",
        "        )\n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(200, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "    @tf.function\n",
        "    def encode(self, x):\n",
        "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "        return mean, logvar\n",
        "    @tf.function\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "    @tf.function\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.decoder(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "        return logits"
      ],
      "metadata": {
        "id": "unLIGpdE-6t-",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:43.810818Z",
          "iopub.execute_input": "2021-11-21T01:12:43.811139Z",
          "iopub.status.idle": "2021-11-21T01:12:43.830275Z",
          "shell.execute_reply.started": "2021-11-21T01:12:43.811107Z",
          "shell.execute_reply": "2021-11-21T01:12:43.829342Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0003,beta_1=0.9, beta_2=0.999,epsilon=1e-08)"
      ],
      "metadata": {
        "id": "HjF7biGGEKML",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:44.481261Z",
          "iopub.execute_input": "2021-11-21T01:12:44.481562Z",
          "iopub.status.idle": "2021-11-21T01:12:44.497145Z",
          "shell.execute_reply.started": "2021-11-21T01:12:44.481534Z",
          "shell.execute_reply": "2021-11-21T01:12:44.496404Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "         -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "          axis=raxis)"
      ],
      "metadata": {
        "id": "o-RrkE6mG9Zp",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:47.064505Z",
          "iopub.execute_input": "2021-11-21T01:12:47.064841Z",
          "iopub.status.idle": "2021-11-21T01:12:47.071907Z",
          "shell.execute_reply.started": "2021-11-21T01:12:47.064811Z",
          "shell.execute_reply": "2021-11-21T01:12:47.070826Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "    mean, logvar = model.encode(x)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "    logpz = log_normal_pdf(z, 0., 0.)\n",
        "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
      ],
      "metadata": {
        "id": "KHmERgizHMAQ",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:48.056459Z",
          "iopub.execute_input": "2021-11-21T01:12:48.056774Z",
          "iopub.status.idle": "2021-11-21T01:12:48.075996Z",
          "shell.execute_reply.started": "2021-11-21T01:12:48.056745Z",
          "shell.execute_reply": "2021-11-21T01:12:48.075331Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Optimization\n",
        "Here we have optimized two lossess, the **KL loss** and **reconstruction loss**.<br>"
      ],
      "metadata": {
        "id": "hiqzUgd9dapY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KL Loss\n",
        "\n",
        "The KL divergence tells us how well the probability distribution Q approximates the probability distribution P by calculating the cross-entropy minus the entropy. Intuitively, you can think of that as the statistical measure of how one distribution differs from another.\n",
        "In VAE, let X be the data we want to model, z be latent variable, P(X) be the probability distribution of data, P(z) be the probability distribution of the latent variable and P(X|z) be the distribution of generating data given latent variable.\n",
        "\n",
        "In the case of variational autoencoders, our objective is to infer P(z)\n",
        "from P(z|X). P(z|X) is the probability distribution that projects our data into latent space. But since we do not have the distribution P(z|X), we estimate it using its simpler estimation Q.\n",
        "\n",
        "Now while training our VAE, the encoder should try to learn the simpler distribution Q(z|X)\n",
        "such that it is as close as possible to the actual distribution P(z|X). This is where we use KL divergence as a measure of a difference between two probability distributions. The VAE objective function thus includes this KL divergence term that needs to be minimized.\n",
        "\n",
        "*DKL[Q(z|X)||P(z|X)] = E[ logQ(z|X) − logP(z|X) ]*"
      ],
      "metadata": {
        "id": "WOouF7vTdapZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconstruction loss\n",
        "As the name suggest, it measures the reconstruction of original input x. This network can be trained by minimizing the reconstruction error, which measures the differences between our original input and the consequent reconstruction."
      ],
      "metadata": {
        "id": "ji1BFUpadapZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "\n",
        "    \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "       This function computes the loss and gradients, and uses the latter to\n",
        "       update the model's parameters.\n",
        "     \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "            mean, logvar = model.encode(x)\n",
        "            z = model.reparameterize(mean, logvar)\n",
        "            x_logit = model.decode(z)\n",
        "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "            logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "            logpz = log_normal_pdf(z, 0., 0.)\n",
        "            logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "            loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                     tf.keras.losses.binary_crossentropy(x, x_logit)\n",
        "                 )\n",
        "            total_loss = reconstruction_loss+ loss_KL\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "id": "PWi7z22ZHO_l",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:51.315725Z",
          "iopub.execute_input": "2021-11-21T01:12:51.316065Z",
          "iopub.status.idle": "2021-11-21T01:12:51.376318Z",
          "shell.execute_reply.started": "2021-11-21T01:12:51.316029Z",
          "shell.execute_reply": "2021-11-21T01:12:51.375353Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keeping the random vector constant for generation (prediction) so\n",
        "# it will be easier to see the improvement.\n",
        "random_vector_for_generation = tf.random.normal(\n",
        "    shape=[num_examples_to_generate, latent_dim])\n",
        "model = CVAE(latent_dim)"
      ],
      "metadata": {
        "id": "zqtNDolCHSao",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:51.988414Z",
          "iopub.execute_input": "2021-11-21T01:12:51.988733Z",
          "iopub.status.idle": "2021-11-21T01:12:52.862647Z",
          "shell.execute_reply.started": "2021-11-21T01:12:51.988704Z",
          "shell.execute_reply": "2021-11-21T01:12:52.861852Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_sample, save):\n",
        "    mean, logvar = model.encode(test_sample)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    predictions = model.sample(z)\n",
        "    fig = plt.figure(figsize=(18, 15))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        wave = np.asarray(predictions[i])\n",
        "        librosa.display.waveplot(wave[0], sr=3000)\n",
        "\n",
        "    # tight_layout minimizes the overlap between 2 sub-plots\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5YymBIlcnMmQ",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:52.867529Z",
          "iopub.execute_input": "2021-11-21T01:12:52.867894Z",
          "iopub.status.idle": "2021-11-21T01:12:52.878565Z",
          "shell.execute_reply.started": "2021-11-21T01:12:52.867858Z",
          "shell.execute_reply": "2021-11-21T01:12:52.877471Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a sample of the test set for generating output images\n",
        "assert BATCH_SIZE >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "    test_sample = test_batch[0]"
      ],
      "metadata": {
        "id": "qB-85OsqoU2B",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:53.447807Z",
          "iopub.execute_input": "2021-11-21T01:12:53.44812Z",
          "iopub.status.idle": "2021-11-21T01:12:59.080441Z",
          "shell.execute_reply.started": "2021-11-21T01:12:53.44809Z",
          "shell.execute_reply": "2021-11-21T01:12:59.079536Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "Yedmk2GNdapa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_images(model, 0, test_sample, 'jazz')\n",
        "def train(train_dataset, test_dataset, model, save):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        start_time = time.time()\n",
        "        for train_x in train_dataset:\n",
        "            train_x = np.asarray(train_x)[0]\n",
        "            train_step(model, train_x, optimizer)\n",
        "        end_time = time.time()\n",
        "\n",
        "        loss = tf.keras.metrics.Mean()\n",
        "        for test_x in test_dataset:\n",
        "            test_x = np.asarray(test_x)[0]\n",
        "            loss(compute_loss(model, test_x))\n",
        "        display.clear_output(wait=False)\n",
        "        elbo = -loss.result()\n",
        "        print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch,\n",
        "                                                                                       elbo,\n",
        "                                                                                       end_time - start_time\n",
        "                                                                                      ))\n",
        "        generate_and_save_images(model,\n",
        "                                 epoch,\n",
        "                                 test_sample,\n",
        "                                 save)\n",
        "train(train_dataset, test_dataset, model, 'jazz')"
      ],
      "metadata": {
        "id": "hTt1sUZMYADG",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:59.084778Z",
          "iopub.execute_input": "2021-11-21T01:12:59.085385Z",
          "iopub.status.idle": "2021-11-21T01:20:09.766149Z",
          "shell.execute_reply.started": "2021-11-21T01:12:59.085341Z",
          "shell.execute_reply": "2021-11-21T01:20:09.764043Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim_file_1 = 'jazz_cvae.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file_1, mode='I') as writer:\n",
        "    filenames = glob.glob('jazz*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "metadata": {
        "id": "pQcs-r6cIoRd",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.285738Z",
          "iopub.status.idle": "2021-11-21T01:12:18.286523Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "6KXnBIl5dapa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file_1)"
      ],
      "metadata": {
        "id": "4lTUTQTmIuRC",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.287739Z",
          "iopub.status.idle": "2021-11-21T01:12:18.288485Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated Music - Jazz\n",
        "Let us listen to the music generated by our model, trained only with jazz music."
      ],
      "metadata": {
        "id": "mNFHLBmmdapa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(test_dataset, model):\n",
        "    save_music = []\n",
        "    for test in test_dataset:\n",
        "        mean, logvar = model.encode(test)\n",
        "        z = model.reparameterize(mean, logvar)\n",
        "        predictions = model.sample(z)\n",
        "        for pred in predictions:\n",
        "            wave = np.asarray(pred)\n",
        "            save_music.append(wave)\n",
        "    return save_music\n",
        "\n",
        "saved_musics = inference(test_dataset, model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.289606Z",
          "iopub.status.idle": "2021-11-21T01:12:18.290345Z"
        },
        "trusted": true,
        "id": "xfi3jP1Odapa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music1=saved_musics[0][0]\n",
        "ipd.Audio(music1,rate=3000)"
      ],
      "metadata": {
        "id": "7VlU5tcEf-cI",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.291651Z",
          "iopub.status.idle": "2021-11-21T01:12:18.292463Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music2=saved_musics[9][0]\n",
        "ipd.Audio(music2,rate=3000)"
      ],
      "metadata": {
        "id": "Pu4LXmx1jF-2",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.293649Z",
          "iopub.status.idle": "2021-11-21T01:12:18.294457Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music3=saved_musics[5][0]\n",
        "ipd.Audio(music3,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.295638Z",
          "iopub.status.idle": "2021-11-21T01:12:18.296491Z"
        },
        "trusted": true,
        "id": "oaz9Kby5dapj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music4=saved_musics[10][0]\n",
        "ipd.Audio(music4,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.297686Z",
          "iopub.status.idle": "2021-11-21T01:12:18.298466Z"
        },
        "trusted": true,
        "id": "tI8okePsdapj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music5=saved_musics[8][0]\n",
        "ipd.Audio(music5,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.299623Z",
          "iopub.status.idle": "2021-11-21T01:12:18.300413Z"
        },
        "trusted": true,
        "id": "Zbnt6BAzdapj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music6=saved_musics[7][0]\n",
        "ipd.Audio(music6,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.301606Z",
          "iopub.status.idle": "2021-11-21T01:12:18.302401Z"
        },
        "trusted": true,
        "id": "30DisGrCdapj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example\n",
        "Let's try out another example with classical music. The code shown below is the same as above, its just the same experiment over a different music category."
      ],
      "metadata": {
        "id": "hm-8dwl3dapj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "rq85ZxPSdapk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrackSet_3, TrackSet_4 = DatasetLoader('classical')"
      ],
      "metadata": {
        "id": "GzuXzwyej7YR",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.305518Z",
          "iopub.status.idle": "2021-11-21T01:12:18.306304Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((TrackSet_3))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "test_dataset = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((TrackSet_4))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "Q6r8z_nkMV5x",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.307474Z",
          "iopub.status.idle": "2021-11-21T01:12:18.308267Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CVAE(latent_dim)"
      ],
      "metadata": {
        "id": "SqseIbNKMe2X",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.311453Z",
          "iopub.status.idle": "2021-11-21T01:12:18.312232Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert BATCH_SIZE >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "    test_sample = test_batch[0]"
      ],
      "metadata": {
        "id": "ZsIIwIOhNCVr",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.313461Z",
          "iopub.status.idle": "2021-11-21T01:12:18.314322Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "         -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "          axis=raxis)\n",
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "    mean, logvar = model.encode(x)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "    logpz = log_normal_pdf(z, 0., 0.)\n",
        "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "\n",
        "    \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "       This function computes the loss and gradients, and uses the latter to\n",
        "       update the model's parameters.\n",
        "     \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "            mean, logvar = model.encode(x)\n",
        "            z = model.reparameterize(mean, logvar)\n",
        "            x_logit = model.decode(z)\n",
        "            cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "            logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "            logpz = log_normal_pdf(z, 0., 0.)\n",
        "            logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "            loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                     tf.keras.losses.binary_crossentropy(x, x_logit)\n",
        "                 )\n",
        "            total_loss = reconstruction_loss+ loss_KL\n",
        "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "metadata": {
        "id": "EFBFqqsrdapk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_images(model, 0, test_sample, 'classical')\n",
        "train(train_dataset, test_dataset, model, 'classical')"
      ],
      "metadata": {
        "id": "6rkkmQCnNHpH",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.315506Z",
          "iopub.status.idle": "2021-11-21T01:12:18.316341Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim_file_2 = 'classical_cvae.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file_2, mode='I') as writer:\n",
        "    filenames = glob.glob('classical*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "metadata": {
        "id": "WAKyCXFrNO8M",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.3175Z",
          "iopub.status.idle": "2021-11-21T01:12:18.318288Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed.embed_file(anim_file_2)"
      ],
      "metadata": {
        "id": "1cKznq16Q5Gg",
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.319516Z",
          "iopub.status.idle": "2021-11-21T01:12:18.320334Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated music - Classical"
      ],
      "metadata": {
        "id": "Gy-Lsj-qdapl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_music_classic = inference(test_dataset, model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.321488Z",
          "iopub.status.idle": "2021-11-21T01:12:18.32231Z"
        },
        "trusted": true,
        "id": "adE-cEmNdapl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music1=save_music_classic[1][0]\n",
        "ipd.Audio(music1,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.323392Z",
          "iopub.status.idle": "2021-11-21T01:12:18.324111Z"
        },
        "trusted": true,
        "id": "dlMMM9Endapl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music2=save_music_classic[9][0]\n",
        "ipd.Audio(music2,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.325217Z",
          "iopub.status.idle": "2021-11-21T01:12:18.325943Z"
        },
        "trusted": true,
        "id": "oRD0e3OHdapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music3=save_music_classic[4][0]\n",
        "ipd.Audio(music3,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.327027Z",
          "iopub.status.idle": "2021-11-21T01:12:18.32783Z"
        },
        "trusted": true,
        "id": "bGBpg8GMdapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music4=save_music_classic[5][0]\n",
        "ipd.Audio(music4,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.328988Z",
          "iopub.status.idle": "2021-11-21T01:12:18.32979Z"
        },
        "trusted": true,
        "id": "XQ7E0woXdapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music5=save_music_classic[8][0]\n",
        "ipd.Audio(music5,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.330858Z",
          "iopub.status.idle": "2021-11-21T01:12:18.331651Z"
        },
        "trusted": true,
        "id": "PTE-Fo4wdapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music6=save_music_classic[7][0]\n",
        "ipd.Audio(music6,rate=3000)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-21T01:12:18.332773Z",
          "iopub.status.idle": "2021-11-21T01:12:18.333509Z"
        },
        "trusted": true,
        "id": "TVp9Rifkdapm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "**WoW! the generated music sounds really good....**\n",
        "![conc](https://i.ytimg.com/vi/PdzFMIDzp2I/maxresdefault.jpg)\n",
        "<br>\n",
        "First of all, I got to learn a lot while working on this project. There are a lot of aspects discussed in the research paper [Jukebox: A Generative Model for Music](https://cdn.openai.com/papers/jukebox.pdf), which could be implemented for better performance and promising result. One of the aspects is the optimization of **Spectral loss**. I have implemented the model which works only for music generation, for generating a lyrical song this model won't generate a promising result. For generating lyrical songs birectional lstm, transformer networks and attention layers would be a better choice according to me for contructing the network architecture. Also, I have trained my model against a particular category of music, this solution could also be made more interesting by training the model against two or more categories of music."
      ],
      "metadata": {
        "id": "w5YRNKzIdapm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thank you.\n",
        "![thank you](https://www.scienceabc.com/wp-content/uploads/2016/06/orkestra-Music-conductor.jpg)"
      ],
      "metadata": {
        "id": "Pn90C4gNdapm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Please <span style=\"color:red\">Up-Vote</span> and <span style=\"color:red\">Share</span> this notebook if you like it or find the content informative. Also, let me know your opinions and suggestions in the comment section below."
      ],
      "metadata": {
        "id": "2rCB6iLCdapn"
      }
    }
  ]
}